# This is an org-mode file, but can be readily converted to Rmarkdown
* Trajectory Response Model

Ideally, we would like to learn a function \(f\) that takes as input
- Site
- Species
- Symbiont Community Information

and returns a "trajectory" (a function of time) in \(\mathbb{R}^d\). This trajectory can be
mapped to a corresponding trajectory in \(\mathbb{R}^p\), which reflects
our \(p\) physiological variables. In particular, we would like for this latter
map to be linear. If \(v(t) \in \mathbb{R}^d\) is a point in the trajectory,
then it corresponds to a point \(u(t) \in \mathbb{R}^p\) with the relationship
\[
u(t) = \sum\limits_{j = 1}^d v_j (t) \gamma_j,
\]
where \(\gamma_j \in \mathbb{R}^p\) is a basis vector. Gathering all of our basis
vectors together as
\[
\Gamma =
\begin{bmatrix}
\gamma_1 & \gamma_2 & \ldots & \gamma_d
\end{bmatrix} \in \mathbb{R}^{p \times d}
\]
we can write this more compactly as
\[
u(t) = \Gamma v(t).
\]
* Reduced Rank Regression
Reduced Rank Regression (RRR) seems a natural starting point to learn a
trajectory of the sort discussed in [[*Trajectory Response Model][Trajectory Response Model]].

RRR is a means of achieving multivariate linear regression with a rank
constraint on the coefficients. Let \(Y \in \mathbb{R}^{n \times q}\) be a
matrix of response variables (one per column).
Let \(X \in \mathbb{R}^{n \times p}\) be a design matrix, and
let \(B \in \mathbb{R}^{p \times q}\) be a matrix of (typically unknown)
regression coefficients. Our model is then
\[
Y = X B + \epsilon.
\]
A natural estimator of \(B\) minimizes the sum of squared errors, i.e.,
\[
B^{\star} \in \operatorname{argmin} \left\lVert Y - X B \right\rVert_F^2,
\]
where \(\left\lVert \cdot \right\rVert_F^2\) denotes the squared Frobenius norm
(i.e., the sum of the squared elements of its argument). A closed form
expression for \(B^{\star}\) is given by
\[
B^{\star} = \left( B^{\intercal} B \right)^{-1} B^{\intercal} Y.
\]
One noteworthy property of this estimator is that it is actually precisely the
same answer if we had separately fit \(q\)-many regression models, one for each
column of \(Y\). However, writing it this way allows us to do more interesting
things when solving the problem simultaneously.

Reduced rank regression essentially finds
\[
B^{\star}_{\text{RRR}(K)} \in
\operatorname*{argmin}_{\operatorname{rank} (B) \leq K}
\left\lVert Y - XB \right\rVert_F^2.
\]
** Modifications
Rather than just fitting vanilla RRR, we will use it as a starting point from
which we can incorporate additional penalties and modeling choices to reflect
the structure of the data. For example, we have repeated observations of the
same units over time.
* Hierarchical Repeated Measures Model
The first version of this was developed during a Zoom meeting involving Dan and
Ishita on [2025-04-08 Tue].

The idea is to have a *latent* part (which is smooth over time) and an observed
part.
** Latent Model
Let \(z_{i, t} \in \mathbb{R}^{d}\) be a latent vector corresponding to
the \(i\)th sample taken at time \(t\).
Let \(L: \left[ n \right] \to \left\{ \text{Mahana, Hilton, Manava} \right\}\)
be a function that maps samples to site, and
let
\(K: \left[ n \right] \to \left\{ \text{Acropora, Pocillopora, Porites} \right\}\)
be a function that maps samples to species.

We want our model for \(z\) to have three properties
1. It should have "smooth" trajectories in \(t\) for a fixed \(i\)
2. It should capture species-specific effects
3. It should be reflect susceptibility to environmental context (e.g., site,
   temperature, pH, etc)

To this end, we propose the following recursive model:
\begin{equation}
\label{eq:z-latent-recursive-model}
z_{i, t} = A w_{i, t} + z_{i, t - 1} + \delta_{i, t},
\end{equation}
where \(w_{i, t} \in \mathbb{R}^{q}\) is a vector holding \(q\) directly
observed context variables, including site
(dummy-coded), \(A \in \mathbb{R}^{d \times q}\) is a coefficient matrix that
encodes how the context variables impact \(z\), and \(\delta_{i, t}\) is random
noise/innovation.
The base case for this model is given by
\begin{equation}
\label{eq:z-latent-base-model}
z_{i, 1} = \mu_{K \left( i \right)} + \delta_{i, 1},
\end{equation}
where \(\mu_{K \left( i \right)}\) is a species-specific intercept,
and \(\delta_{i, 1}\) is random noise/innovation.
** Observation Model
Let \(x_{i, t} \in \mathbb{R}^{p}\) hold the observed data from the \(i\)th
sample at time \(t\). In our current data, \(p = 11\). First, let's assume a
very generic observation model:
\begin{equation}
\label{eq:x-observation-generic-model}
x_{i, t} = f \left( z_{i, t} \right) + \epsilon_{i, t},
\end{equation}
where \(f: \mathbb{R}^{d} \to \mathbb{R}^{p}\) is a function that maps the
latent variable \(z\) to the observed variable \(x\), and \(\epsilon_{i, t}\) is
random noise. Next, we turn our attention to \(f\).

Suppose that \(f\) is linear. Then we can rewrite the above model as 
\begin{equation}
\label{eq:x-observation-linear-model}
x_{i, t} = B z_{i, t} + \epsilon_{i, t},
\end{equation}
where \(B \in \mathbb{R}^{p \times d}\) is a matrix of coefficients.
In order to render the model easier to interpret, we can instead over-parameterize our model, and
rewrite it as
\begin{equation}
\label{eq:x-observation-linear-overparam-model}
x_{i, t} = B z_{i, t} + B^{\left( K \left( i \right) \right)} z_{i, t} + \epsilon_{i, t}.
\end{equation}

* org-mode config

* Spell Check
#  LocalWords:  Symbiont
